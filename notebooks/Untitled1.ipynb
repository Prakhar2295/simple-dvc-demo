{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03d111ae-595c-4680-ae71-6d5a5e2fe5f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--config CONFIG]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f C:\\Users\\prath\\AppData\\Roaming\\jupyter\\runtime\\kernel-d786fa9c-5e74-4afe-be68-5f83361e5c3a.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prath\\anaconda3\\envs\\wineq\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3465: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "from src.get_data import read_params\n",
    "import argparse\n",
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "from pprint import pprint\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "\n",
    "def log_production_model(config_path):\n",
    "    config = read_params(config_path)\n",
    "\n",
    "    mlflow_config = config[\"mlflow_config\"]\n",
    "\n",
    "    model_name = mlflow_config[\"registered_model_name\"]\n",
    "\n",
    "    remote_server_uri = mlflow_config[\"remote_server_uri\"]\n",
    "\n",
    "    mlflow.set_registry_uri(remote_server_uri)\n",
    "\n",
    "    runs = mlflow.search_runs(experiment_ids=1)\n",
    "    lowest = runs[\"metrics.mae\"].sort_values(ascending=True)[0]\n",
    "    lowest_run_id = runs[runs[\"metrics.mae\"] == lowest][\"run_id\"][0]\n",
    "\n",
    "    client = MlflowClient()\n",
    "    for mv in client.search_model_versions(f\"name='{model_name}'\"):\n",
    "        mv = dict(mv)\n",
    "\n",
    "        if mv[\"run_id\"] == lowest_run_id:\n",
    "            current_version = mv[\"version\"]\n",
    "            logged_model = mv[\"source\"]\n",
    "            pprint(mv, indent=4)\n",
    "            client.transition_model_version_stage(\n",
    "                name=model_name,\n",
    "                version=current_version,\n",
    "                stage=\"Production\"\n",
    "            )\n",
    "        else:\n",
    "            current_version = mv[\"version\"]\n",
    "            logged_model = mv[\"source\"]\n",
    "            pprint(mv, indent=4)\n",
    "            client.transition_model_version_stage(\n",
    "                name=model_name,\n",
    "                version=current_version,\n",
    "                stage=\"Staging\"\n",
    "            )\n",
    "\n",
    "    loaded_model = mlflow.pyfunc.load_model(logged_model)\n",
    "\n",
    "    model_path = config[\"webapp_model_dir\"]  # \"prediction_service/model\"\n",
    "\n",
    "    joblib.dump(loaded_model, model_path)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    args = argparse.ArgumentParser()\n",
    "    args.add_argument(\"--config\", default=\"params.yaml\")\n",
    "    parsed_args = args.parse_args()\n",
    "    data = log_production_model(config_path=parsed_args.config)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54d00d7c-432a-442b-8425-a8b96b108b74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'creation_timestamp': 1666704489766,\n",
      "    'current_stage': 'Staging',\n",
      "    'description': '',\n",
      "    'last_updated_timestamp': 1666722369603,\n",
      "    'name': 'ElasticNetWineModel',\n",
      "    'run_id': '62cb741093534138a13b296fbabc9291',\n",
      "    'run_link': '',\n",
      "    'source': './artifacts/1/62cb741093534138a13b296fbabc9291/artifacts/model',\n",
      "    'status': 'READY',\n",
      "    'status_message': '',\n",
      "    'tags': {},\n",
      "    'user_id': '',\n",
      "    'version': '1'}\n",
      "{   'creation_timestamp': 1666704822299,\n",
      "    'current_stage': 'Staging',\n",
      "    'description': '',\n",
      "    'last_updated_timestamp': 1666722369575,\n",
      "    'name': 'ElasticNetWineModel',\n",
      "    'run_id': '01b0e44c1c2e43f6907ce32c95a264d2',\n",
      "    'run_link': '',\n",
      "    'source': './artifacts/1/01b0e44c1c2e43f6907ce32c95a264d2/artifacts/model',\n",
      "    'status': 'READY',\n",
      "    'status_message': '',\n",
      "    'tags': {},\n",
      "    'user_id': '',\n",
      "    'version': '2'}\n",
      "{   'creation_timestamp': 1666704929800,\n",
      "    'current_stage': 'Staging',\n",
      "    'description': '',\n",
      "    'last_updated_timestamp': 1666722369554,\n",
      "    'name': 'ElasticNetWineModel',\n",
      "    'run_id': '47cdb12d25c7440b96151db58bd7c8ac',\n",
      "    'run_link': '',\n",
      "    'source': './artifacts/1/47cdb12d25c7440b96151db58bd7c8ac/artifacts/model',\n",
      "    'status': 'READY',\n",
      "    'status_message': '',\n",
      "    'tags': {},\n",
      "    'user_id': '',\n",
      "    'version': '3'}\n",
      "{   'creation_timestamp': 1666706723838,\n",
      "    'current_stage': 'Production',\n",
      "    'description': '',\n",
      "    'last_updated_timestamp': 1666722369520,\n",
      "    'name': 'ElasticNetWineModel',\n",
      "    'run_id': '252b36e2b8f349498be8e619f48f7794',\n",
      "    'run_link': '',\n",
      "    'source': './artifacts/1/252b36e2b8f349498be8e619f48f7794/artifacts/model',\n",
      "    'status': 'READY',\n",
      "    'status_message': '',\n",
      "    'tags': {},\n",
      "    'user_id': '',\n",
      "    'version': '4'}\n"
     ]
    }
   ],
   "source": [
    "from src.get_data import read_params\n",
    "import argparse\n",
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "from pprint import pprint\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "os.chdir('C:/Users/prath/Downloads/WaferMLops')\n",
    "\n",
    "\n",
    "def log_production_model(config_path):\n",
    "    config = read_params(config_path)\n",
    "    \n",
    "    \n",
    "    mlflow_config = config[\"mlflow_config\"] \n",
    "    \n",
    "\n",
    "    model_name = mlflow_config[\"registered_model_name\"]\n",
    "\n",
    "\n",
    "    remote_server_uri = mlflow_config[\"remote_server_uri\"]\n",
    "\n",
    "    mlflow.set_tracking_uri(remote_server_uri)\n",
    "    \n",
    "    \n",
    "    runs = mlflow.search_runs([1])\n",
    "    lowest = runs[\"metrics.mae\"].sort_values(ascending=True)[0]\n",
    "    lowest_run_id = runs[runs[\"metrics.mae\"] == lowest][\"run_id\"][0]\n",
    "    \n",
    "\n",
    "    client = MlflowClient()\n",
    "    for mv in client.search_model_versions(f\"name='{model_name}'\"):\n",
    "        mv = dict(mv)\n",
    "        pprint(mv, indent=4)\n",
    "        \n",
    "#         if mv[\"run_id\"] == lowest_run_id:\n",
    "#             current_version = mv[\"version\"]\n",
    "#             logged_model = mv[\"source\"]\n",
    "#             pprint(mv, indent=4)\n",
    "#             client.transition_model_version_stage(\n",
    "#                 name=model_name,\n",
    "#                 version=current_version,\n",
    "#                 stage=\"Production\"\n",
    "#             )\n",
    "#         else:\n",
    "#             current_version = mv[\"version\"]\n",
    "#             client.transition_model_version_stage(\n",
    "#                 name=model_name,\n",
    "#                 version=current_version,\n",
    "#                 stage=\"Staging\"\n",
    "#             )        \n",
    "\n",
    "\n",
    "#     loaded_model = mlflow.pyfunc.load_model(logged_model)\n",
    "    \n",
    "#     model_path = config[\"webapp_model_dir\"] #\"prediction_service/model\"\n",
    "\n",
    "#     joblib.dump(loaded_model, model_path)\n",
    "\n",
    "log_production_model(\"params.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "613829b6-f293-461b-bf00-4013ac9906f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C is OS\n",
      " Volume Serial Number is 3E87-CA83\n",
      "\n",
      " Directory of C:\\Users\\prath\\Downloads\\WaferMLops\n",
      "\n",
      "25-10-2022  23:19    <DIR>          .\n",
      "25-10-2022  23:19    <DIR>          ..\n",
      "06-10-2022  18:36    <DIR>          .dvc\n",
      "06-10-2022  18:36               142 .dvcignore\n",
      "18-10-2022  17:24    <DIR>          .github\n",
      "06-10-2022  18:36             1,928 .gitignore\n",
      "25-10-2022  23:03    <DIR>          .idea\n",
      "09-10-2022  22:45    <DIR>          .pytest_cache\n",
      "13-10-2022  12:37    <DIR>          .tox\n",
      "20-10-2022  22:00             1,213 app.py\n",
      "25-10-2022  18:58    <DIR>          artifacts\n",
      "06-10-2022  18:36    <DIR>          data\n",
      "08-10-2022  21:45    <DIR>          data_given\n",
      "25-10-2022  19:35             1,581 dvc.lock\n",
      "25-10-2022  23:19             1,079 dvc.yaml\n",
      "06-10-2022  18:36                 0 main.py\n",
      "25-10-2022  19:35           135,168 mlflow.db\n",
      "23-10-2022  17:12    <DIR>          mlruns\n",
      "25-10-2022  23:41    <DIR>          notebooks\n",
      "25-10-2022  19:35               910 params.yaml\n",
      "21-10-2022  10:09    <DIR>          prediction_service\n",
      "20-10-2022  15:49                20 Procfile\n",
      "08-10-2022  18:22               739 readme.md\n",
      "14-10-2022  22:20    <DIR>          report\n",
      "21-10-2022  18:02               169 requirements.txt\n",
      "14-10-2022  22:20    <DIR>          saved_models\n",
      "11-10-2022  19:54               210 setup.py\n",
      "25-10-2022  23:24    <DIR>          src\n",
      "21-10-2022  18:05    <DIR>          src.egg-info\n",
      "06-10-2022  18:36               463 template.py\n",
      "21-10-2022  09:29    <DIR>          tests\n",
      "13-10-2022  12:37               112 tox.ini\n",
      "06-10-2022  14:48    <DIR>          venv\n",
      "13-10-2022  17:16    <DIR>          webapp\n",
      "              14 File(s)        143,734 bytes\n",
      "              20 Dir(s)  26,296,410,112 bytes free\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de303d0-9775-4f86-be00-4c105d87da26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
